{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # for google colab users\n",
    "    import google.colab  # type: ignore\n",
    "    from google.colab import output\n",
    "\n",
    "    COLAB = True\n",
    "    %pip install sae-lens transformer-lens\n",
    "except:\n",
    "    # for local setup\n",
    "    COLAB = False\n",
    "    from IPython import get_ipython  # type: ignore\n",
    "\n",
    "    ipython = get_ipython()\n",
    "    assert ipython is not None\n",
    "    ipython.run_line_magic(\"load_ext\", \"autoreload\")\n",
    "    ipython.run_line_magic(\"autoreload\", \"2\")\n",
    "\n",
    "# Imports for displaying vis in Colab / notebook\n",
    "import webbrowser\n",
    "import http.server\n",
    "import socketserver\n",
    "import threading\n",
    "\n",
    "PORT = 8000\n",
    "\n",
    "# general imports\n",
    "import os\n",
    "import torch as t\n",
    "from tqdm import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_vis_inline(filename: str, height: int = 850):\n",
    "    \"\"\"\n",
    "    Displays the HTML files in Colab. Uses global `PORT` variable defined in prev cell, so that each\n",
    "    vis has a unique port without having to define a port within the function.\n",
    "    \"\"\"\n",
    "    if not (COLAB):\n",
    "        webbrowser.open(filename)\n",
    "    else:\n",
    "        global PORT\n",
    "\n",
    "        def serve(directory):\n",
    "            os.chdir(directory)\n",
    "\n",
    "            # Create a handler for serving files\n",
    "            handler = http.server.SimpleHTTPRequestHandler\n",
    "\n",
    "            # Create a socket server with the handler\n",
    "            with socketserver.TCPServer((\"\", PORT), handler) as httpd:\n",
    "                print(f\"Serving files from {directory} on port {PORT}\")\n",
    "                httpd.serve_forever()\n",
    "\n",
    "        thread = threading.Thread(target=serve, args=(\"/content\",))\n",
    "        thread.start()\n",
    "\n",
    "        output.serve_kernel_port_as_iframe(\n",
    "            PORT, path=f\"/{filename}\", height=height, cache_in_notebook=True\n",
    "        )\n",
    "\n",
    "        PORT += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# package import\n",
    "from torch import Tensor\n",
    "from transformer_lens import utils\n",
    "from functools import partial\n",
    "from jaxtyping import Int, Float\n",
    "\n",
    "# device setup\n",
    "if torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"\n",
    "else:\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n",
      "SAEConfig(architecture='standard', d_in=768, d_sae=24576, activation_fn_str='relu', apply_b_dec_to_input=True, finetuning_scaling_factor=False, context_size=128, model_name='gpt2-small', hook_name='blocks.5.hook_resid_pre', hook_layer=5, hook_head_index=None, prepend_bos=True, dataset_path='Skylion007/openwebtext', dataset_trust_remote_code=True, normalize_activations='none', dtype='torch.float32', device='cuda', sae_lens_training_version=None, activation_fn_kwargs={}, neuronpedia_id='gpt2-small/5-res-jb')\n",
      "blocks.5.hook_resid_pre\n"
     ]
    }
   ],
   "source": [
    "from transformer_lens import HookedTransformer\n",
    "from sae_lens import SAE\n",
    "from sae_lens.toolkit.pretrained_saes import get_gpt2_res_jb_saes\n",
    "\n",
    "# Choose a layer you want to focus on\n",
    "# For this tutorial, we're going to use layer 2\n",
    "layer = 5\n",
    "\n",
    "# get model\n",
    "model = HookedTransformer.from_pretrained(\n",
    "    \"gpt2-small\",\n",
    "    device=DEVICE,\n",
    ")\n",
    "\n",
    "# get the SAE for this layer\n",
    "sae, cfg_dict, _ = SAE.from_pretrained(\n",
    "    release=\"gpt2-small-res-jb\", sae_id=f\"blocks.{layer}.hook_resid_pre\", device=DEVICE\n",
    ")\n",
    "\n",
    "print(sae.cfg)\n",
    "\n",
    "# get hook point\n",
    "hook_point = sae.cfg.hook_name\n",
    "print(hook_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: tensor([[50256,   383,  8407, 12816, 10290]], device='cuda:0')\n",
      "Token strings: ['<|endoftext|>', ' The', ' Golden', ' Gate', ' Bridge']\n",
      "\n",
      "Top 3 feature activations:\n",
      "tensor([[[639.8358, 519.3585, 463.5883],\n",
      "         [ 18.4421,  18.1516,   7.2985],\n",
      "         [ 53.0257,   7.6162,   5.8503],\n",
      "         [ 19.2280,  17.0333,   7.8110],\n",
      "         [ 38.3003,   6.2576,   5.5530]]], device='cuda:0')\n",
      "\n",
      "Top 3 feature indices:\n",
      "tensor([[[ 4242,  1334, 12411],\n",
      "         [19946, 12384,  8814],\n",
      "         [12308,  3820,  5686],\n",
      "         [ 7544,  6053,  1546],\n",
      "         [17274,  6053, 20939]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sv_prompt = \" The Golden Gate Bridge\"\n",
    "sv_logits, cache = model.run_with_cache(sv_prompt, prepend_bos=True)\n",
    "tokens = model.to_tokens(sv_prompt)\n",
    "print(f\"Tokens: {tokens}\")\n",
    "print(f\"Token strings: {model.to_str_tokens(tokens)}\")\n",
    "\n",
    "# get the feature activations from our SAE\n",
    "sv_feature_acts = sae.encode(cache[hook_point])\n",
    "\n",
    "# get sae_out\n",
    "sae_out = sae.decode(sv_feature_acts)\n",
    "\n",
    "k = 3\n",
    "sv_feature_acts_topk_vals, sv_feature_acts_topk_indices = t.topk(sv_feature_acts, k)\n",
    "\n",
    "# print out the top activations, focus on the indices\n",
    "print(f\"\\nTop {k} feature activations:\\n{sv_feature_acts_topk_vals}\")\n",
    "print(f\"\\nTop {k} feature indices:\\n{sv_feature_acts_topk_indices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://neuronpedia.org/quick-list/?name=temporary_list&features=%5B%7B%22modelId%22%3A%20%22gpt2-small%22%2C%20%22layer%22%3A%20%225-res-jb%22%2C%20%22index%22%3A%20%22%5B%5B4242%2C%201334%2C%2012411%5D%2C%20%5B19946%2C%2012384%2C%208814%5D%2C%20%5B12308%2C%203820%2C%205686%5D%2C%20%5B7544%2C%206053%2C%201546%5D%2C%20%5B17274%2C%206053%2C%2020939%5D%5D%22%7D%5D'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sae_lens.analysis.neuronpedia_integration import get_neuronpedia_quick_list\n",
    "\n",
    "get_neuronpedia_quick_list(sae=sae, features=sv_feature_acts_topk_indices.tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
